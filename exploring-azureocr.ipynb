{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-ai-documentintelligence==1.0.0b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get Configuration Settings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "key = os.getenv(\"DOCUMENT_INTELLIGENCE_SUBSCRIPTION_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(page, line):\n",
    "    result = []\n",
    "    for word in page.words:\n",
    "        if _in_span(word, line.spans):\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "# To learn the detailed concept of \"span\" in the following codes, visit: https://aka.ms/spans \n",
    "def _in_span(word, spans):\n",
    "    for span in spans:\n",
    "        if word.span.offset >= span.offset and (word.span.offset + word.span.length) <= (span.offset + span.length):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_read():\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "    from azure.ai.documentintelligence.models import DocumentAnalysisFeature, AnalyzeResult, AnalyzeDocumentRequest\n",
    "\n",
    "    # For how to obtain the endpoint and key, please see PREREQUISITES above.\n",
    "    endpoint = os.environ[\"DOCUMENT_INTELLIGENCE_ENDPOINT\"]\n",
    "    key = os.environ[\"DOCUMENT_INTELLIGENCE_SUBSCRIPTION_KEY\"]\n",
    "\n",
    "    document_intelligence_client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "    # Analyze a document at a URL:\n",
    "    formUrl = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/rest-api/read.png\"\n",
    "    # Replace with your actual formUrl:\n",
    "    # If you use the URL of a public website, to find more URLs, please visit: https://aka.ms/more-URLs \n",
    "    # If you analyze a document in Blob Storage, you need to generate Public SAS URL, please visit: https://aka.ms/create-sas-tokens\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-read\",\n",
    "        AnalyzeDocumentRequest(url_source=formUrl),\n",
    "        features=[DocumentAnalysisFeature.LANGUAGES]\n",
    "    )       \n",
    "    \n",
    "    # # If analyzing a local document, remove the comment markers (#) at the beginning of these 11 lines.\n",
    "    # # Delete or comment out the part of \"Analyze a document at a URL\" above.\n",
    "    # # Replace <path to your sample file>  with your actual file path.\n",
    "    # path_to_sample_document = \"<path to your sample file>\"\n",
    "    # with open(path_to_sample_document, \"rb\") as f:\n",
    "    #     poller = document_intelligence_client.begin_analyze_document(\n",
    "    #         \"prebuilt-read\",\n",
    "    #         analyze_request=f,\n",
    "    #         features=[DocumentAnalysisFeature.LANGUAGES],\n",
    "    #         content_type=\"application/octet-stream\",\n",
    "    #     )\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    \n",
    "    # [START analyze_read]\n",
    "    # Detect languages.\n",
    "    print(\"----Languages detected in the document----\")\n",
    "    if result.languages is not None:\n",
    "        for language in result.languages:\n",
    "            print(f\"Language code: '{language.locale}' with confidence {language.confidence}\")\n",
    "    \n",
    "    # To learn the detailed concept of \"bounding polygon\" in the following content, visit: https://aka.ms/bounding-region\n",
    "    # Analyze pages.\n",
    "    for page in result.pages:\n",
    "        print(f\"----Analyzing document from page #{page.page_number}----\")\n",
    "        print(f\"Page has width: {page.width} and height: {page.height}, measured with unit: {page.unit}\")\n",
    "\n",
    "        # Analyze lines.\n",
    "        if page.lines:\n",
    "            for line_idx, line in enumerate(page.lines):\n",
    "                words = get_words(page, line)\n",
    "                print(\n",
    "                    f\"...Line # {line_idx} has {len(words)} words and text '{line.content}' within bounding polygon '{line.polygon}'\"\n",
    "                )\n",
    "\n",
    "                # Analyze words.\n",
    "                for word in words:\n",
    "                    print(f\"......Word '{word.content}' has a confidence of {word.confidence}\")\n",
    "        \n",
    "    # Analyze paragraphs.\n",
    "    if result.paragraphs:\n",
    "        print(f\"----Detected #{len(result.paragraphs)} paragraphs in the document----\")\n",
    "        for paragraph in result.paragraphs:\n",
    "            print(f\"Found paragraph within {paragraph.bounding_regions} bounding region\")\n",
    "            print(f\"...with content: '{paragraph.content}'\")\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "    # [END analyze_read]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Languages detected in the document----\n",
      "Language code: 'en' with confidence 1\n",
      "Language code: 'en' with confidence 0.95\n",
      "Language code: 'en' with confidence 0.8\n",
      "Language code: 'en' with confidence 0.9\n",
      "Language code: 'en' with confidence 0.99\n",
      "Language code: 'en' with confidence 0.7\n",
      "----Analyzing document from page #1----\n",
      "Page has width: 915 and height: 1190, measured with unit: LengthUnit.PIXEL\n",
      "...Line # 0 has 13 words and text 'While healthcare is still in the early stages of its Al journey, we' within bounding polygon '[259, 55, 817, 56, 817, 78, 259, 76]'\n",
      "......Word 'While' has a confidence of 0.996\n",
      "......Word 'healthcare' has a confidence of 0.995\n",
      "......Word 'is' has a confidence of 0.999\n",
      "......Word 'still' has a confidence of 0.997\n",
      "......Word 'in' has a confidence of 0.998\n",
      "......Word 'the' has a confidence of 0.999\n",
      "......Word 'early' has a confidence of 0.997\n",
      "......Word 'stages' has a confidence of 0.997\n",
      "......Word 'of' has a confidence of 0.999\n",
      "......Word 'its' has a confidence of 0.998\n",
      "......Word 'Al' has a confidence of 0.952\n",
      "......Word 'journey,' has a confidence of 0.995\n",
      "......Word 'we' has a confidence of 0.998\n",
      "...Line # 1 has 8 words and text 'are seeing pharmaceutical and other life sciences organizations' within bounding polygon '[259, 84, 826, 83, 826, 105, 259, 106]'\n",
      "......Word 'are' has a confidence of 0.995\n",
      "......Word 'seeing' has a confidence of 0.992\n",
      "......Word 'pharmaceutical' has a confidence of 0.993\n",
      "......Word 'and' has a confidence of 0.999\n",
      "......Word 'other' has a confidence of 0.997\n",
      "......Word 'life' has a confidence of 0.991\n",
      "......Word 'sciences' has a confidence of 0.994\n",
      "......Word 'organizations' has a confidence of 0.992\n",
      "...Line # 2 has 8 words and text 'making major investments in Al and related technologies.\"' within bounding polygon '[259, 112, 783, 112, 783, 134, 259, 134]'\n",
      "......Word 'making' has a confidence of 0.994\n",
      "......Word 'major' has a confidence of 0.994\n",
      "......Word 'investments' has a confidence of 0.993\n",
      "......Word 'in' has a confidence of 0.995\n",
      "......Word 'Al' has a confidence of 0.898\n",
      "......Word 'and' has a confidence of 0.995\n",
      "......Word 'related' has a confidence of 0.995\n",
      "......Word 'technologies.\"' has a confidence of 0.929\n",
      "...Line # 3 has 13 words and text 'TOM LAWRY | National Director for Al, Health and Life Sciences | Microsoft' within bounding polygon '[258, 151, 637, 151, 637, 167, 258, 166]'\n",
      "......Word 'TOM' has a confidence of 0.997\n",
      "......Word 'LAWRY' has a confidence of 0.995\n",
      "......Word '|' has a confidence of 0.684\n",
      "......Word 'National' has a confidence of 0.989\n",
      "......Word 'Director' has a confidence of 0.992\n",
      "......Word 'for' has a confidence of 0.995\n",
      "......Word 'Al,' has a confidence of 0.943\n",
      "......Word 'Health' has a confidence of 0.995\n",
      "......Word 'and' has a confidence of 0.994\n",
      "......Word 'Life' has a confidence of 0.993\n",
      "......Word 'Sciences' has a confidence of 0.988\n",
      "......Word '|' has a confidence of 0.83\n",
      "......Word 'Microsoft' has a confidence of 0.992\n",
      "...Line # 4 has 8 words and text 'As pharmaceutical and other life sciences organizations invest' within bounding polygon '[75, 240, 424, 241, 424, 257, 75, 257]'\n",
      "......Word 'As' has a confidence of 0.995\n",
      "......Word 'pharmaceutical' has a confidence of 0.989\n",
      "......Word 'and' has a confidence of 0.993\n",
      "......Word 'other' has a confidence of 0.997\n",
      "......Word 'life' has a confidence of 0.992\n",
      "......Word 'sciences' has a confidence of 0.994\n",
      "......Word 'organizations' has a confidence of 0.992\n",
      "......Word 'invest' has a confidence of 0.994\n",
      "...Line # 5 has 10 words and text 'in and deploy advanced technologies, they are beginning to see' within bounding polygon '[76, 259, 436, 260, 436, 277, 76, 276]'\n",
      "......Word 'in' has a confidence of 0.995\n",
      "......Word 'and' has a confidence of 0.992\n",
      "......Word 'deploy' has a confidence of 0.997\n",
      "......Word 'advanced' has a confidence of 0.993\n",
      "......Word 'technologies,' has a confidence of 0.992\n",
      "......Word 'they' has a confidence of 0.989\n",
      "......Word 'are' has a confidence of 0.995\n",
      "......Word 'beginning' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'see' has a confidence of 0.999\n",
      "...Line # 6 has 8 words and text 'benefits in diverse areas across their organizations. Companies' within bounding polygon '[77, 277, 427, 278, 427, 295, 77, 294]'\n",
      "......Word 'benefits' has a confidence of 0.993\n",
      "......Word 'in' has a confidence of 0.996\n",
      "......Word 'diverse' has a confidence of 0.995\n",
      "......Word 'areas' has a confidence of 0.994\n",
      "......Word 'across' has a confidence of 0.997\n",
      "......Word 'their' has a confidence of 0.995\n",
      "......Word 'organizations.' has a confidence of 0.989\n",
      "......Word 'Companies' has a confidence of 0.995\n",
      "...Line # 7 has 8 words and text 'are looking to incorporate automation and continuing smart' within bounding polygon '[76, 296, 414, 296, 414, 313, 76, 312]'\n",
      "......Word 'are' has a confidence of 0.998\n",
      "......Word 'looking' has a confidence of 0.996\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'incorporate' has a confidence of 0.992\n",
      "......Word 'automation' has a confidence of 0.994\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'continuing' has a confidence of 0.992\n",
      "......Word 'smart' has a confidence of 0.997\n",
      "...Line # 8 has 9 words and text 'factory investments to reduce costs in drug discovery, research' within bounding polygon '[77, 314, 428, 314, 428, 330, 77, 330]'\n",
      "......Word 'factory' has a confidence of 0.995\n",
      "......Word 'investments' has a confidence of 0.99\n",
      "......Word 'to' has a confidence of 0.992\n",
      "......Word 'reduce' has a confidence of 0.995\n",
      "......Word 'costs' has a confidence of 0.996\n",
      "......Word 'in' has a confidence of 0.997\n",
      "......Word 'drug' has a confidence of 0.992\n",
      "......Word 'discovery,' has a confidence of 0.993\n",
      "......Word 'research' has a confidence of 0.992\n",
      "...Line # 9 has 7 words and text 'and development, and manufacturing and supply chain' within bounding polygon '[75, 332, 388, 332, 388, 348, 75, 348]'\n",
      "......Word 'and' has a confidence of 0.997\n",
      "......Word 'development,' has a confidence of 0.992\n",
      "......Word 'and' has a confidence of 0.999\n",
      "......Word 'manufacturing' has a confidence of 0.992\n",
      "......Word 'and' has a confidence of 0.999\n",
      "......Word 'supply' has a confidence of 0.994\n",
      "......Word 'chain' has a confidence of 0.996\n",
      "...Line # 10 has 8 words and text 'management. Many life sciences organizations are also choosing' within bounding polygon '[76, 350, 441, 350, 441, 366, 76, 367]'\n",
      "......Word 'management.' has a confidence of 0.992\n",
      "......Word 'Many' has a confidence of 0.992\n",
      "......Word 'life' has a confidence of 0.992\n",
      "......Word 'sciences' has a confidence of 0.993\n",
      "......Word 'organizations' has a confidence of 0.992\n",
      "......Word 'are' has a confidence of 0.998\n",
      "......Word 'also' has a confidence of 0.992\n",
      "......Word 'choosing' has a confidence of 0.996\n",
      "...Line # 11 has 11 words and text 'to stay with more virtual approaches in the \"new normal\" -' within bounding polygon '[76, 368, 407, 368, 407, 384, 76, 385]'\n",
      "......Word 'to' has a confidence of 0.997\n",
      "......Word 'stay' has a confidence of 0.992\n",
      "......Word 'with' has a confidence of 0.987\n",
      "......Word 'more' has a confidence of 0.988\n",
      "......Word 'virtual' has a confidence of 0.992\n",
      "......Word 'approaches' has a confidence of 0.992\n",
      "......Word 'in' has a confidence of 0.998\n",
      "......Word 'the' has a confidence of 0.998\n",
      "......Word '\"new' has a confidence of 0.948\n",
      "......Word 'normal\"' has a confidence of 0.948\n",
      "......Word '-' has a confidence of 0.977\n",
      "...Line # 12 has 9 words and text 'particularly in clinical trials and sales and marketing areas.' within bounding polygon '[77, 386, 397, 386, 397, 403, 77, 403]'\n",
      "......Word 'particularly' has a confidence of 0.987\n",
      "......Word 'in' has a confidence of 0.996\n",
      "......Word 'clinical' has a confidence of 0.987\n",
      "......Word 'trials' has a confidence of 0.993\n",
      "......Word 'and' has a confidence of 0.997\n",
      "......Word 'sales' has a confidence of 0.995\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'marketing' has a confidence of 0.993\n",
      "......Word 'areas.' has a confidence of 0.975\n",
      "...Line # 13 has 3 words and text 'Enhancing the patient' within bounding polygon '[77, 422, 268, 423, 268, 446, 77, 446]'\n",
      "......Word 'Enhancing' has a confidence of 0.994\n",
      "......Word 'the' has a confidence of 0.999\n",
      "......Word 'patient' has a confidence of 0.997\n",
      "...Line # 14 has 3 words and text 'and provider experience' within bounding polygon '[76, 447, 285, 447, 284, 469, 76, 469]'\n",
      "......Word 'and' has a confidence of 0.999\n",
      "......Word 'provider' has a confidence of 0.995\n",
      "......Word 'experience' has a confidence of 0.995\n",
      "...Line # 15 has 9 words and text 'Clinical trial sponsors are continually seeking to make clinical' within bounding polygon '[76, 481, 425, 481, 425, 498, 76, 499]'\n",
      "......Word 'Clinical' has a confidence of 0.993\n",
      "......Word 'trial' has a confidence of 0.995\n",
      "......Word 'sponsors' has a confidence of 0.994\n",
      "......Word 'are' has a confidence of 0.993\n",
      "......Word 'continually' has a confidence of 0.992\n",
      "......Word 'seeking' has a confidence of 0.996\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'make' has a confidence of 0.992\n",
      "......Word 'clinical' has a confidence of 0.994\n",
      "...Line # 16 has 10 words and text 'trials faster and to improve the experience for patients and' within bounding polygon '[76, 500, 414, 500, 414, 516, 76, 516]'\n",
      "......Word 'trials' has a confidence of 0.993\n",
      "......Word 'faster' has a confidence of 0.994\n",
      "......Word 'and' has a confidence of 0.997\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'improve' has a confidence of 0.995\n",
      "......Word 'the' has a confidence of 0.998\n",
      "......Word 'experience' has a confidence of 0.994\n",
      "......Word 'for' has a confidence of 0.995\n",
      "......Word 'patients' has a confidence of 0.992\n",
      "......Word 'and' has a confidence of 0.997\n",
      "...Line # 17 has 7 words and text 'physicians. The COVID-19 pandemic has accelerated the' within bounding polygon '[76, 517, 410, 517, 410, 534, 76, 535]'\n",
      "......Word 'physicians.' has a confidence of 0.989\n",
      "......Word 'The' has a confidence of 0.993\n",
      "......Word 'COVID-19' has a confidence of 0.992\n",
      "......Word 'pandemic' has a confidence of 0.992\n",
      "......Word 'has' has a confidence of 0.992\n",
      "......Word 'accelerated' has a confidence of 0.992\n",
      "......Word 'the' has a confidence of 0.998\n",
      "...Line # 18 has 9 words and text 'adoption of decentralized clinical trials, with an increase in' within bounding polygon '[75, 535, 410, 535, 410, 552, 75, 553]'\n",
      "......Word 'adoption' has a confidence of 0.994\n",
      "......Word 'of' has a confidence of 0.996\n",
      "......Word 'decentralized' has a confidence of 0.992\n",
      "......Word 'clinical' has a confidence of 0.993\n",
      "......Word 'trials,' has a confidence of 0.992\n",
      "......Word 'with' has a confidence of 0.989\n",
      "......Word 'an' has a confidence of 0.998\n",
      "......Word 'increase' has a confidence of 0.993\n",
      "......Word 'in' has a confidence of 0.995\n",
      "...Line # 19 has 8 words and text 'trial activities conducted remotely and in participants' homes.' within bounding polygon '[77, 554, 428, 554, 428, 571, 77, 571]'\n",
      "......Word 'trial' has a confidence of 0.993\n",
      "......Word 'activities' has a confidence of 0.992\n",
      "......Word 'conducted' has a confidence of 0.992\n",
      "......Word 'remotely' has a confidence of 0.993\n",
      "......Word 'and' has a confidence of 0.997\n",
      "......Word 'in' has a confidence of 0.995\n",
      "......Word 'participants'' has a confidence of 0.933\n",
      "......Word 'homes.' has a confidence of 0.975\n",
      "...Line # 20 has 11 words and text 'In a Mckinsey survey,1 up to 98 percent of patients reported' within bounding polygon '[77, 572, 422, 572, 422, 589, 77, 589]'\n",
      "......Word 'In' has a confidence of 0.992\n",
      "......Word 'a' has a confidence of 0.989\n",
      "......Word 'Mckinsey' has a confidence of 0.987\n",
      "......Word 'survey,1' has a confidence of 0.684\n",
      "......Word 'up' has a confidence of 0.994\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word '98' has a confidence of 0.995\n",
      "......Word 'percent' has a confidence of 0.994\n",
      "......Word 'of' has a confidence of 0.997\n",
      "......Word 'patients' has a confidence of 0.994\n",
      "......Word 'reported' has a confidence of 0.992\n",
      "...Line # 21 has 10 words and text 'satisfaction with telemedicine. In the same report, 72 percent of' within bounding polygon '[76, 591, 442, 591, 442, 607, 76, 607]'\n",
      "......Word 'satisfaction' has a confidence of 0.992\n",
      "......Word 'with' has a confidence of 0.99\n",
      "......Word 'telemedicine.' has a confidence of 0.992\n",
      "......Word 'In' has a confidence of 0.994\n",
      "......Word 'the' has a confidence of 0.997\n",
      "......Word 'same' has a confidence of 0.989\n",
      "......Word 'report,' has a confidence of 0.992\n",
      "......Word '72' has a confidence of 0.995\n",
      "......Word 'percent' has a confidence of 0.992\n",
      "......Word 'of' has a confidence of 0.983\n",
      "...Line # 22 has 8 words and text 'physicians surveyed reported similar or better experiences with' within bounding polygon '[77, 609, 439, 609, 439, 626, 77, 627]'\n",
      "......Word 'physicians' has a confidence of 0.993\n",
      "......Word 'surveyed' has a confidence of 0.994\n",
      "......Word 'reported' has a confidence of 0.992\n",
      "......Word 'similar' has a confidence of 0.994\n",
      "......Word 'or' has a confidence of 0.998\n",
      "......Word 'better' has a confidence of 0.993\n",
      "......Word 'experiences' has a confidence of 0.975\n",
      "......Word 'with' has a confidence of 0.992\n",
      "...Line # 23 has 6 words and text 'remote engagement compared with in-person visits.' within bounding polygon '[76, 628, 377, 627, 377, 643, 76, 644]'\n",
      "......Word 'remote' has a confidence of 0.996\n",
      "......Word 'engagement' has a confidence of 0.995\n",
      "......Word 'compared' has a confidence of 0.995\n",
      "......Word 'with' has a confidence of 0.984\n",
      "......Word 'in-person' has a confidence of 0.995\n",
      "......Word 'visits.' has a confidence of 0.992\n",
      "...Line # 24 has 12 words and text 'The shift of trial activities closer to patients has been enabled by' within bounding polygon '[74, 657, 445, 658, 444, 674, 74, 673]'\n",
      "......Word 'The' has a confidence of 0.999\n",
      "......Word 'shift' has a confidence of 0.996\n",
      "......Word 'of' has a confidence of 0.982\n",
      "......Word 'trial' has a confidence of 0.993\n",
      "......Word 'activities' has a confidence of 0.992\n",
      "......Word 'closer' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'patients' has a confidence of 0.993\n",
      "......Word 'has' has a confidence of 0.996\n",
      "......Word 'been' has a confidence of 0.992\n",
      "......Word 'enabled' has a confidence of 0.994\n",
      "......Word 'by' has a confidence of 0.998\n",
      "...Line # 25 has 9 words and text 'a myriad of evolving technologies and services (e.g., electronic' within bounding polygon '[76, 676, 438, 676, 438, 693, 76, 693]'\n",
      "......Word 'a' has a confidence of 0.993\n",
      "......Word 'myriad' has a confidence of 0.988\n",
      "......Word 'of' has a confidence of 0.992\n",
      "......Word 'evolving' has a confidence of 0.992\n",
      "......Word 'technologies' has a confidence of 0.992\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'services' has a confidence of 0.993\n",
      "......Word '(e.g.,' has a confidence of 0.988\n",
      "......Word 'electronic' has a confidence of 0.993\n",
      "...Line # 26 has 8 words and text 'consent, telehealth and remote patient monitoring). The aim' within bounding polygon '[76, 694, 428, 694, 428, 710, 76, 710]'\n",
      "......Word 'consent,' has a confidence of 0.993\n",
      "......Word 'telehealth' has a confidence of 0.993\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'remote' has a confidence of 0.997\n",
      "......Word 'patient' has a confidence of 0.996\n",
      "......Word 'monitoring).' has a confidence of 0.992\n",
      "......Word 'The' has a confidence of 0.999\n",
      "......Word 'aim' has a confidence of 0.998\n",
      "...Line # 27 has 9 words and text 'to use technology to improve the patient experience and' within bounding polygon '[76, 712, 405, 712, 405, 728, 76, 728]'\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'use' has a confidence of 0.997\n",
      "......Word 'technology' has a confidence of 0.994\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'improve' has a confidence of 0.996\n",
      "......Word 'the' has a confidence of 0.997\n",
      "......Word 'patient' has a confidence of 0.994\n",
      "......Word 'experience' has a confidence of 0.995\n",
      "......Word 'and' has a confidence of 0.998\n",
      "...Line # 28 has 10 words and text 'convenience has also broadened trial access to reach a broader,' within bounding polygon '[76, 730, 443, 730, 443, 746, 76, 746]'\n",
      "......Word 'convenience' has a confidence of 0.993\n",
      "......Word 'has' has a confidence of 0.994\n",
      "......Word 'also' has a confidence of 0.992\n",
      "......Word 'broadened' has a confidence of 0.992\n",
      "......Word 'trial' has a confidence of 0.995\n",
      "......Word 'access' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'reach' has a confidence of 0.994\n",
      "......Word 'a' has a confidence of 0.994\n",
      "......Word 'broader,' has a confidence of 0.992\n",
      "...Line # 29 has 4 words and text 'more diverse patient population.' within bounding polygon '[76, 748, 265, 748, 265, 765, 76, 764]'\n",
      "......Word 'more' has a confidence of 0.992\n",
      "......Word 'diverse' has a confidence of 0.993\n",
      "......Word 'patient' has a confidence of 0.994\n",
      "......Word 'population.' has a confidence of 0.99\n",
      "...Line # 30 has 10 words and text '\"It's an interesting and exciting time right now,\" said Keren' within bounding polygon '[74, 779, 406, 779, 406, 796, 74, 796]'\n",
      "......Word '\"It's' has a confidence of 0.911\n",
      "......Word 'an' has a confidence of 0.997\n",
      "......Word 'interesting' has a confidence of 0.991\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'exciting' has a confidence of 0.995\n",
      "......Word 'time' has a confidence of 0.992\n",
      "......Word 'right' has a confidence of 0.997\n",
      "......Word 'now,\"' has a confidence of 0.973\n",
      "......Word 'said' has a confidence of 0.992\n",
      "......Word 'Keren' has a confidence of 0.997\n",
      "...Line # 31 has 7 words and text 'Priyadarshini, Regional Business Lead - Asia, Worldwide' within bounding polygon '[76, 798, 402, 797, 402, 814, 76, 815]'\n",
      "......Word 'Priyadarshini,' has a confidence of 0.978\n",
      "......Word 'Regional' has a confidence of 0.992\n",
      "......Word 'Business' has a confidence of 0.992\n",
      "......Word 'Lead' has a confidence of 0.992\n",
      "......Word '-' has a confidence of 0.994\n",
      "......Word 'Asia,' has a confidence of 0.994\n",
      "......Word 'Worldwide' has a confidence of 0.992\n",
      "...Line # 32 has 10 words and text 'Health, Microsoft. \"It used to be that physicians were key.' within bounding polygon '[76, 815, 407, 816, 407, 833, 76, 832]'\n",
      "......Word 'Health,' has a confidence of 0.993\n",
      "......Word 'Microsoft.' has a confidence of 0.992\n",
      "......Word '\"It' has a confidence of 0.847\n",
      "......Word 'used' has a confidence of 0.984\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'be' has a confidence of 0.998\n",
      "......Word 'that' has a confidence of 0.992\n",
      "......Word 'physicians' has a confidence of 0.995\n",
      "......Word 'were' has a confidence of 0.992\n",
      "......Word 'key.' has a confidence of 0.988\n",
      "...Line # 33 has 8 words and text 'Now, suddenly, patients are feeling empowered by technology.' within bounding polygon '[76, 834, 438, 834, 438, 851, 76, 850]'\n",
      "......Word 'Now,' has a confidence of 0.992\n",
      "......Word 'suddenly,' has a confidence of 0.994\n",
      "......Word 'patients' has a confidence of 0.995\n",
      "......Word 'are' has a confidence of 0.997\n",
      "......Word 'feeling' has a confidence of 0.993\n",
      "......Word 'empowered' has a confidence of 0.995\n",
      "......Word 'by' has a confidence of 0.998\n",
      "......Word 'technology.' has a confidence of 0.992\n",
      "...Line # 34 has 7 words and text 'Pharmaceutical companies and other life sciences companies' within bounding polygon '[77, 852, 429, 852, 429, 869, 77, 868]'\n",
      "......Word 'Pharmaceutical' has a confidence of 0.992\n",
      "......Word 'companies' has a confidence of 0.993\n",
      "......Word 'and' has a confidence of 0.993\n",
      "......Word 'other' has a confidence of 0.995\n",
      "......Word 'life' has a confidence of 0.987\n",
      "......Word 'sciences' has a confidence of 0.992\n",
      "......Word 'companies' has a confidence of 0.992\n",
      "...Line # 35 has 10 words and text 'are realizing they have to pay attention to the patient' within bounding polygon '[76, 870, 384, 870, 384, 887, 76, 887]'\n",
      "......Word 'are' has a confidence of 0.998\n",
      "......Word 'realizing' has a confidence of 0.994\n",
      "......Word 'they' has a confidence of 0.992\n",
      "......Word 'have' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'pay' has a confidence of 0.998\n",
      "......Word 'attention' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'the' has a confidence of 0.997\n",
      "......Word 'patient' has a confidence of 0.996\n",
      "...Line # 36 has 7 words and text 'experience in addition to the physician experience.\"' within bounding polygon '[76, 888, 372, 888, 372, 905, 76, 905]'\n",
      "......Word 'experience' has a confidence of 0.993\n",
      "......Word 'in' has a confidence of 0.996\n",
      "......Word 'addition' has a confidence of 0.994\n",
      "......Word 'to' has a confidence of 0.995\n",
      "......Word 'the' has a confidence of 0.998\n",
      "......Word 'physician' has a confidence of 0.993\n",
      "......Word 'experience.\"' has a confidence of 0.92\n",
      "...Line # 37 has 9 words and text 'Enhanced patient experiences can be delivered in many different' within bounding polygon '[77, 918, 443, 918, 443, 935, 77, 935]'\n",
      "......Word 'Enhanced' has a confidence of 0.993\n",
      "......Word 'patient' has a confidence of 0.992\n",
      "......Word 'experiences' has a confidence of 0.99\n",
      "......Word 'can' has a confidence of 0.998\n",
      "......Word 'be' has a confidence of 0.994\n",
      "......Word 'delivered' has a confidence of 0.994\n",
      "......Word 'in' has a confidence of 0.996\n",
      "......Word 'many' has a confidence of 0.994\n",
      "......Word 'different' has a confidence of 0.992\n",
      "...Line # 38 has 11 words and text 'ways. One example of a life sciences product that leverages the' within bounding polygon '[76, 937, 433, 937, 433, 953, 76, 953]'\n",
      "......Word 'ways.' has a confidence of 0.992\n",
      "......Word 'One' has a confidence of 0.998\n",
      "......Word 'example' has a confidence of 0.994\n",
      "......Word 'of' has a confidence of 0.996\n",
      "......Word 'a' has a confidence of 0.994\n",
      "......Word 'life' has a confidence of 0.989\n",
      "......Word 'sciences' has a confidence of 0.995\n",
      "......Word 'product' has a confidence of 0.993\n",
      "......Word 'that' has a confidence of 0.992\n",
      "......Word 'leverages' has a confidence of 0.994\n",
      "......Word 'the' has a confidence of 0.999\n",
      "...Line # 39 has 10 words and text 'intelligent cloud to directly affect the patient experience is the' within bounding polygon '[76, 955, 426, 955, 426, 971, 76, 972]'\n",
      "......Word 'intelligent' has a confidence of 0.991\n",
      "......Word 'cloud' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.995\n",
      "......Word 'directly' has a confidence of 0.994\n",
      "......Word 'affect' has a confidence of 0.992\n",
      "......Word 'the' has a confidence of 0.997\n",
      "......Word 'patient' has a confidence of 0.995\n",
      "......Word 'experience' has a confidence of 0.992\n",
      "......Word 'is' has a confidence of 0.996\n",
      "......Word 'the' has a confidence of 0.999\n",
      "...Line # 40 has 9 words and text 'Tandem® Diabetes Care insulin pump. The Tandem® t:slim X2' within bounding polygon '[74, 972, 423, 972, 423, 989, 74, 989]'\n",
      "......Word 'Tandem®' has a confidence of 0.807\n",
      "......Word 'Diabetes' has a confidence of 0.992\n",
      "......Word 'Care' has a confidence of 0.987\n",
      "......Word 'insulin' has a confidence of 0.992\n",
      "......Word 'pump.' has a confidence of 0.98\n",
      "......Word 'The' has a confidence of 0.997\n",
      "......Word 'Tandem®' has a confidence of 0.671\n",
      "......Word 't:slim' has a confidence of 0.989\n",
      "......Word 'X2' has a confidence of 0.982\n",
      "...Line # 41 has 8 words and text 'insulin pump with Basal-IQ technology enables patients with' within bounding polygon '[75, 991, 417, 991, 417, 1007, 75, 1007]'\n",
      "......Word 'insulin' has a confidence of 0.993\n",
      "......Word 'pump' has a confidence of 0.992\n",
      "......Word 'with' has a confidence of 0.992\n",
      "......Word 'Basal-IQ' has a confidence of 0.949\n",
      "......Word 'technology' has a confidence of 0.994\n",
      "......Word 'enables' has a confidence of 0.994\n",
      "......Word 'patients' has a confidence of 0.994\n",
      "......Word 'with' has a confidence of 0.992\n",
      "...Line # 42 has 12 words and text 'Type 1 diabetes to predict and prevent the low levels of blood' within bounding polygon '[75, 1008, 420, 1008, 420, 1025, 75, 1026]'\n",
      "......Word 'Type' has a confidence of 0.992\n",
      "......Word '1' has a confidence of 0.992\n",
      "......Word 'diabetes' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'predict' has a confidence of 0.994\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'prevent' has a confidence of 0.992\n",
      "......Word 'the' has a confidence of 0.998\n",
      "......Word 'low' has a confidence of 0.995\n",
      "......Word 'levels' has a confidence of 0.993\n",
      "......Word 'of' has a confidence of 0.998\n",
      "......Word 'blood' has a confidence of 0.995\n",
      "...Line # 43 has 7 words and text 'sugar that cause hypoglycemia.2 The algorithm-driven, software-' within bounding polygon '[75, 1027, 441, 1026, 441, 1043, 75, 1044]'\n",
      "......Word 'sugar' has a confidence of 0.995\n",
      "......Word 'that' has a confidence of 0.992\n",
      "......Word 'cause' has a confidence of 0.997\n",
      "......Word 'hypoglycemia.2' has a confidence of 0.977\n",
      "......Word 'The' has a confidence of 0.996\n",
      "......Word 'algorithm-driven,' has a confidence of 0.992\n",
      "......Word 'software-' has a confidence of 0.995\n",
      "...Line # 44 has 8 words and text 'updatable pump improves the patient experience by automating' within bounding polygon '[77, 1045, 440, 1045, 440, 1062, 77, 1062]'\n",
      "......Word 'updatable' has a confidence of 0.992\n",
      "......Word 'pump' has a confidence of 0.988\n",
      "......Word 'improves' has a confidence of 0.992\n",
      "......Word 'the' has a confidence of 0.997\n",
      "......Word 'patient' has a confidence of 0.995\n",
      "......Word 'experience' has a confidence of 0.992\n",
      "......Word 'by' has a confidence of 0.998\n",
      "......Word 'automating' has a confidence of 0.993\n",
      "...Line # 45 has 8 words and text 'chronic disease management and eliminating the need for' within bounding polygon '[76, 1063, 404, 1063, 404, 1079, 76, 1079]'\n",
      "......Word 'chronic' has a confidence of 0.992\n",
      "......Word 'disease' has a confidence of 0.994\n",
      "......Word 'management' has a confidence of 0.992\n",
      "......Word 'and' has a confidence of 0.999\n",
      "......Word 'eliminating' has a confidence of 0.992\n",
      "......Word 'the' has a confidence of 0.997\n",
      "......Word 'need' has a confidence of 0.992\n",
      "......Word 'for' has a confidence of 0.993\n",
      "...Line # 46 has 7 words and text 'constant finger pricks to check glucose levels.' within bounding polygon '[77, 1081, 332, 1081, 332, 1097, 77, 1098]'\n",
      "......Word 'constant' has a confidence of 0.995\n",
      "......Word 'finger' has a confidence of 0.996\n",
      "......Word 'pricks' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'check' has a confidence of 0.993\n",
      "......Word 'glucose' has a confidence of 0.994\n",
      "......Word 'levels.' has a confidence of 0.987\n",
      "...Line # 47 has 10 words and text 'Tandem was able to create and deploy this innovation by' within bounding polygon '[465, 240, 793, 240, 793, 257, 465, 257]'\n",
      "......Word 'Tandem' has a confidence of 0.973\n",
      "......Word 'was' has a confidence of 0.996\n",
      "......Word 'able' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.995\n",
      "......Word 'create' has a confidence of 0.995\n",
      "......Word 'and' has a confidence of 0.996\n",
      "......Word 'deploy' has a confidence of 0.996\n",
      "......Word 'this' has a confidence of 0.992\n",
      "......Word 'innovation' has a confidence of 0.994\n",
      "......Word 'by' has a confidence of 0.992\n",
      "...Line # 48 has 9 words and text 'leveraging the Al and machine learning capabilities of the' within bounding polygon '[468, 260, 801, 259, 801, 276, 468, 276]'\n",
      "......Word 'leveraging' has a confidence of 0.992\n",
      "......Word 'the' has a confidence of 0.996\n",
      "......Word 'Al' has a confidence of 0.952\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'machine' has a confidence of 0.995\n",
      "......Word 'learning' has a confidence of 0.977\n",
      "......Word 'capabilities' has a confidence of 0.992\n",
      "......Word 'of' has a confidence of 0.998\n",
      "......Word 'the' has a confidence of 0.999\n",
      "...Line # 49 has 9 words and text 'intelligent cloud. As Al and other technologies continue to' within bounding polygon '[468, 278, 807, 278, 807, 294, 468, 294]'\n",
      "......Word 'intelligent' has a confidence of 0.992\n",
      "......Word 'cloud.' has a confidence of 0.992\n",
      "......Word 'As' has a confidence of 0.993\n",
      "......Word 'Al' has a confidence of 0.988\n",
      "......Word 'and' has a confidence of 0.999\n",
      "......Word 'other' has a confidence of 0.997\n",
      "......Word 'technologies' has a confidence of 0.993\n",
      "......Word 'continue' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.998\n",
      "...Line # 50 has 10 words and text 'advance, potential use cases will multiply. \"Speed to value is' within bounding polygon '[468, 296, 812, 296, 812, 312, 468, 313]'\n",
      "......Word 'advance,' has a confidence of 0.992\n",
      "......Word 'potential' has a confidence of 0.992\n",
      "......Word 'use' has a confidence of 0.993\n",
      "......Word 'cases' has a confidence of 0.994\n",
      "......Word 'will' has a confidence of 0.992\n",
      "......Word 'multiply.' has a confidence of 0.974\n",
      "......Word '\"Speed' has a confidence of 0.946\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'value' has a confidence of 0.995\n",
      "......Word 'is' has a confidence of 0.993\n",
      "...Line # 51 has 7 words and text 'going to continue to accelerate,\" said Lawry.' within bounding polygon '[468, 315, 724, 314, 724, 330, 468, 331]'\n",
      "......Word 'going' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'continue' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.992\n",
      "......Word 'accelerate,\"' has a confidence of 0.977\n",
      "......Word 'said' has a confidence of 0.992\n",
      "......Word 'Lawry.' has a confidence of 0.992\n",
      "...Line # 52 has 7 words and text 'In addition to enhancing the patient experience,' within bounding polygon '[468, 344, 744, 345, 744, 362, 468, 361]'\n",
      "......Word 'In' has a confidence of 0.993\n",
      "......Word 'addition' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'enhancing' has a confidence of 0.995\n",
      "......Word 'the' has a confidence of 0.999\n",
      "......Word 'patient' has a confidence of 0.995\n",
      "......Word 'experience,' has a confidence of 0.99\n",
      "...Line # 53 has 7 words and text 'pharmaceutical and other life sciences companies can' within bounding polygon '[469, 363, 778, 363, 778, 380, 469, 379]'\n",
      "......Word 'pharmaceutical' has a confidence of 0.991\n",
      "......Word 'and' has a confidence of 0.995\n",
      "......Word 'other' has a confidence of 0.995\n",
      "......Word 'life' has a confidence of 0.992\n",
      "......Word 'sciences' has a confidence of 0.993\n",
      "......Word 'companies' has a confidence of 0.994\n",
      "......Word 'can' has a confidence of 0.999\n",
      "...Line # 54 has 7 words and text 'leverage advanced technologies to improve relationships with' within bounding polygon '[466, 381, 823, 381, 823, 397, 466, 398]'\n",
      "......Word 'leverage' has a confidence of 0.993\n",
      "......Word 'advanced' has a confidence of 0.993\n",
      "......Word 'technologies' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'improve' has a confidence of 0.995\n",
      "......Word 'relationships' has a confidence of 0.992\n",
      "......Word 'with' has a confidence of 0.992\n",
      "...Line # 55 has 9 words and text 'providers. For example, COVID-19 is driving changes in the' within bounding polygon '[469, 398, 815, 398, 815, 415, 469, 416]'\n",
      "......Word 'providers.' has a confidence of 0.977\n",
      "......Word 'For' has a confidence of 0.995\n",
      "......Word 'example,' has a confidence of 0.992\n",
      "......Word 'COVID-19' has a confidence of 0.992\n",
      "......Word 'is' has a confidence of 0.995\n",
      "......Word 'driving' has a confidence of 0.992\n",
      "......Word 'changes' has a confidence of 0.993\n",
      "......Word 'in' has a confidence of 0.998\n",
      "......Word 'the' has a confidence of 0.996\n",
      "...Line # 56 has 8 words and text 'way companies interact with clinicians. Prior to COVID-19,' within bounding polygon '[468, 418, 805, 416, 805, 433, 468, 435]'\n",
      "......Word 'way' has a confidence of 0.998\n",
      "......Word 'companies' has a confidence of 0.993\n",
      "......Word 'interact' has a confidence of 0.992\n",
      "......Word 'with' has a confidence of 0.992\n",
      "......Word 'clinicians.' has a confidence of 0.985\n",
      "......Word 'Prior' has a confidence of 0.995\n",
      "......Word 'to' has a confidence of 0.995\n",
      "......Word 'COVID-19,' has a confidence of 0.959\n",
      "...Line # 57 has 9 words and text '75 percent of physicians preferred in-person sales visits from' within bounding polygon '[467, 435, 816, 434, 816, 451, 467, 452]'\n",
      "......Word '75' has a confidence of 0.992\n",
      "......Word 'percent' has a confidence of 0.993\n",
      "......Word 'of' has a confidence of 0.995\n",
      "......Word 'physicians' has a confidence of 0.992\n",
      "......Word 'preferred' has a confidence of 0.992\n",
      "......Word 'in-person' has a confidence of 0.991\n",
      "......Word 'sales' has a confidence of 0.995\n",
      "......Word 'visits' has a confidence of 0.992\n",
      "......Word 'from' has a confidence of 0.994\n",
      "...Line # 58 has 9 words and text 'medtech reps; likewise, 77 percent of physicians preferred in-' within bounding polygon '[468, 453, 818, 453, 818, 470, 468, 470]'\n",
      "......Word 'medtech' has a confidence of 0.995\n",
      "......Word 'reps;' has a confidence of 0.994\n",
      "......Word 'likewise,' has a confidence of 0.994\n",
      "......Word '77' has a confidence of 0.997\n",
      "......Word 'percent' has a confidence of 0.995\n",
      "......Word 'of' has a confidence of 0.999\n",
      "......Word 'physicians' has a confidence of 0.995\n",
      "......Word 'preferred' has a confidence of 0.995\n",
      "......Word 'in-' has a confidence of 0.994\n",
      "...Line # 59 has 6 words and text 'person sales visits from pharma reps.3' within bounding polygon '[468, 471, 685, 471, 685, 487, 468, 488]'\n",
      "......Word 'person' has a confidence of 0.995\n",
      "......Word 'sales' has a confidence of 0.993\n",
      "......Word 'visits' has a confidence of 0.994\n",
      "......Word 'from' has a confidence of 0.993\n",
      "......Word 'pharma' has a confidence of 0.992\n",
      "......Word 'reps.3' has a confidence of 0.969\n",
      "...Line # 60 has 7 words and text 'Since the advent of COVID-19, however, physician' within bounding polygon '[468, 502, 772, 502, 772, 519, 468, 519]'\n",
      "......Word 'Since' has a confidence of 0.996\n",
      "......Word 'the' has a confidence of 0.998\n",
      "......Word 'advent' has a confidence of 0.992\n",
      "......Word 'of' has a confidence of 0.997\n",
      "......Word 'COVID-19,' has a confidence of 0.992\n",
      "......Word 'however,' has a confidence of 0.995\n",
      "......Word 'physician' has a confidence of 0.993\n",
      "...Line # 61 has 9 words and text 'preferences are moving toward virtual visits. Only 53 percent' within bounding polygon '[468, 521, 828, 521, 828, 537, 468, 538]'\n",
      "......Word 'preferences' has a confidence of 0.992\n",
      "......Word 'are' has a confidence of 0.992\n",
      "......Word 'moving' has a confidence of 0.995\n",
      "......Word 'toward' has a confidence of 0.995\n",
      "......Word 'virtual' has a confidence of 0.992\n",
      "......Word 'visits.' has a confidence of 0.992\n",
      "......Word 'Only' has a confidence of 0.992\n",
      "......Word '53' has a confidence of 0.992\n",
      "......Word 'percent' has a confidence of 0.995\n",
      "...Line # 62 has 9 words and text 'of physicians now express a preference for in-person visits' within bounding polygon '[468, 539, 812, 539, 812, 556, 468, 556]'\n",
      "......Word 'of' has a confidence of 0.997\n",
      "......Word 'physicians' has a confidence of 0.992\n",
      "......Word 'now' has a confidence of 0.998\n",
      "......Word 'express' has a confidence of 0.993\n",
      "......Word 'a' has a confidence of 0.984\n",
      "......Word 'preference' has a confidence of 0.992\n",
      "......Word 'for' has a confidence of 0.995\n",
      "......Word 'in-person' has a confidence of 0.992\n",
      "......Word 'visits' has a confidence of 0.992\n",
      "...Line # 63 has 10 words and text 'from medtech reps and only 40 percent prefer in-person visits' within bounding polygon '[469, 556, 835, 557, 835, 574, 469, 573]'\n",
      "......Word 'from' has a confidence of 0.992\n",
      "......Word 'medtech' has a confidence of 0.994\n",
      "......Word 'reps' has a confidence of 0.992\n",
      "......Word 'and' has a confidence of 0.998\n",
      "......Word 'only' has a confidence of 0.989\n",
      "......Word '40' has a confidence of 0.997\n",
      "......Word 'percent' has a confidence of 0.992\n",
      "......Word 'prefer' has a confidence of 0.992\n",
      "......Word 'in-person' has a confidence of 0.994\n",
      "......Word 'visits' has a confidence of 0.992\n",
      "...Line # 64 has 10 words and text 'from pharma reps.4 That puts the onus on pharmaceutical and' within bounding polygon '[469, 574, 835, 575, 835, 591, 469, 591]'\n",
      "......Word 'from' has a confidence of 0.992\n",
      "......Word 'pharma' has a confidence of 0.993\n",
      "......Word 'reps.4' has a confidence of 0.828\n",
      "......Word 'That' has a confidence of 0.992\n",
      "......Word 'puts' has a confidence of 0.992\n",
      "......Word 'the' has a confidence of 0.998\n",
      "......Word 'onus' has a confidence of 0.992\n",
      "......Word 'on' has a confidence of 0.998\n",
      "......Word 'pharmaceutical' has a confidence of 0.989\n",
      "......Word 'and' has a confidence of 0.998\n",
      "...Line # 65 has 8 words and text 'life sciences organizations to deliver valuable and engaging' within bounding polygon '[468, 593, 818, 593, 818, 610, 468, 609]'\n",
      "......Word 'life' has a confidence of 0.992\n",
      "......Word 'sciences' has a confidence of 0.994\n",
      "......Word 'organizations' has a confidence of 0.994\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'deliver' has a confidence of 0.995\n",
      "......Word 'valuable' has a confidence of 0.994\n",
      "......Word 'and' has a confidence of 0.999\n",
      "......Word 'engaging' has a confidence of 0.996\n",
      "...Line # 66 has 4 words and text 'virtual visits to providers.' within bounding polygon '[468, 611, 617, 611, 617, 627, 468, 627]'\n",
      "......Word 'virtual' has a confidence of 0.992\n",
      "......Word 'visits' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'providers.' has a confidence of 0.992\n",
      "...Line # 67 has 12 words and text 'One way to do that is to leverage text analytics capabilities to' within bounding polygon '[468, 641, 822, 641, 822, 659, 468, 659]'\n",
      "......Word 'One' has a confidence of 0.997\n",
      "......Word 'way' has a confidence of 0.996\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'do' has a confidence of 0.995\n",
      "......Word 'that' has a confidence of 0.992\n",
      "......Word 'is' has a confidence of 0.997\n",
      "......Word 'to' has a confidence of 0.998\n",
      "......Word 'leverage' has a confidence of 0.994\n",
      "......Word 'text' has a confidence of 0.992\n",
      "......Word 'analytics' has a confidence of 0.993\n",
      "......Word 'capabilities' has a confidence of 0.992\n",
      "......Word 'to' has a confidence of 0.999\n",
      "...Line # 68 has 8 words and text 'enhance the provider information stored in the organization's' within bounding polygon '[468, 660, 821, 660, 821, 676, 468, 676]'\n",
      "......Word 'enhance' has a confidence of 0.994\n",
      "......Word 'the' has a confidence of 0.998\n",
      "......Word 'provider' has a confidence of 0.994\n",
      "......Word 'information' has a confidence of 0.992\n",
      "......Word 'stored' has a confidence of 0.995\n",
      "......Word 'in' has a confidence of 0.995\n",
      "......Word 'the' has a confidence of 0.999\n",
      "......Word 'organization's' has a confidence of 0.963\n",
      "...Line # 69 has 6 words and text 'customer relationship management (CRM) system. For' within bounding polygon '[467, 678, 789, 678, 789, 694, 467, 695]'\n",
      "......Word 'customer' has a confidence of 0.995\n",
      "......Word 'relationship' has a confidence of 0.993\n",
      "......Word 'management' has a confidence of 0.992\n",
      "......Word '(CRM)' has a confidence of 0.992\n",
      "......Word 'system.' has a confidence of 0.993\n",
      "......Word 'For' has a confidence of 0.999\n",
      "...Line # 70 has 13 words and text 'example, a rep setting up a visit with 'Dr. X' could run text' within bounding polygon '[468, 697, 801, 695, 801, 711, 468, 713]'\n",
      "......Word 'example,' has a confidence of 0.977\n",
      "......Word 'a' has a confidence of 0.994\n",
      "......Word 'rep' has a confidence of 0.996\n",
      "......Word 'setting' has a confidence of 0.994\n",
      "......Word 'up' has a confidence of 0.977\n",
      "......Word 'a' has a confidence of 0.993\n",
      "......Word 'visit' has a confidence of 0.992\n",
      "......Word 'with' has a confidence of 0.989\n",
      "......Word ''Dr.' has a confidence of 0.963\n",
      "......Word 'X'' has a confidence of 0.939\n",
      "......Word 'could' has a confidence of 0.996\n",
      "......Word 'run' has a confidence of 0.995\n",
      "......Word 'text' has a confidence of 0.993\n",
      "...Line # 71 has 10 words and text 'analytics on publicly available resources on the web to identify' within bounding polygon '[467, 714, 825, 713, 825, 730, 467, 731]'\n",
      "......Word 'analytics' has a confidence of 0.992\n",
      "......Word 'on' has a confidence of 0.998\n",
      "......Word 'publicly' has a confidence of 0.992\n",
      "......Word 'available' has a confidence of 0.994\n",
      "......Word 'resources' has a confidence of 0.994\n",
      "......Word 'on' has a confidence of 0.993\n",
      "......Word 'the' has a confidence of 0.995\n",
      "......Word 'web' has a confidence of 0.997\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'identify' has a confidence of 0.994\n",
      "...Line # 72 has 11 words and text 'on which specific topics Dr. X has been writing about and' within bounding polygon '[468, 731, 800, 731, 800, 748, 468, 748]'\n",
      "......Word 'on' has a confidence of 0.998\n",
      "......Word 'which' has a confidence of 0.995\n",
      "......Word 'specific' has a confidence of 0.992\n",
      "......Word 'topics' has a confidence of 0.993\n",
      "......Word 'Dr.' has a confidence of 0.993\n",
      "......Word 'X' has a confidence of 0.992\n",
      "......Word 'has' has a confidence of 0.996\n",
      "......Word 'been' has a confidence of 0.992\n",
      "......Word 'writing' has a confidence of 0.995\n",
      "......Word 'about' has a confidence of 0.996\n",
      "......Word 'and' has a confidence of 0.999\n",
      "...Line # 73 has 8 words and text 'commenting. \"All kinds of publicly available information can' within bounding polygon '[468, 750, 813, 750, 813, 766, 468, 767]'\n",
      "......Word 'commenting.' has a confidence of 0.992\n",
      "......Word '\"All' has a confidence of 0.95\n",
      "......Word 'kinds' has a confidence of 0.995\n",
      "......Word 'of' has a confidence of 0.998\n",
      "......Word 'publicly' has a confidence of 0.992\n",
      "......Word 'available' has a confidence of 0.993\n",
      "......Word 'information' has a confidence of 0.993\n",
      "......Word 'can' has a confidence of 0.998\n",
      "...Line # 74 has 4 words and text 'All kinds of publicly' within bounding polygon '[466, 828, 645, 829, 645, 851, 466, 850]'\n",
      "......Word 'All' has a confidence of 0.989\n",
      "......Word 'kinds' has a confidence of 0.997\n",
      "......Word 'of' has a confidence of 0.992\n",
      "......Word 'publicly' has a confidence of 0.995\n",
      "...Line # 75 has 2 words and text 'available information' within bounding polygon '[468, 857, 662, 856, 662, 877, 468, 877]'\n",
      "......Word 'available' has a confidence of 0.994\n",
      "......Word 'information' has a confidence of 0.992\n",
      "...Line # 76 has 5 words and text 'can be mined with text' within bounding polygon '[468, 886, 674, 886, 674, 905, 468, 906]'\n",
      "......Word 'can' has a confidence of 0.998\n",
      "......Word 'be' has a confidence of 0.995\n",
      "......Word 'mined' has a confidence of 0.993\n",
      "......Word 'with' has a confidence of 0.992\n",
      "......Word 'text' has a confidence of 0.983\n",
      "...Line # 77 has 2 words and text 'analytics technology,' within bounding polygon '[467, 915, 662, 915, 662, 937, 467, 936]'\n",
      "......Word 'analytics' has a confidence of 0.992\n",
      "......Word 'technology,' has a confidence of 0.992\n",
      "...Line # 78 has 7 words and text 'which can be used to arm the' within bounding polygon '[468, 942, 730, 942, 730, 964, 468, 964]'\n",
      "......Word 'which' has a confidence of 0.998\n",
      "......Word 'can' has a confidence of 0.999\n",
      "......Word 'be' has a confidence of 0.999\n",
      "......Word 'used' has a confidence of 0.99\n",
      "......Word 'to' has a confidence of 0.999\n",
      "......Word 'arm' has a confidence of 0.994\n",
      "......Word 'the' has a confidence of 0.998\n",
      "...Line # 79 has 6 words and text 'sales rep with relevant information even' within bounding polygon '[468, 972, 830, 972, 830, 992, 468, 992]'\n",
      "......Word 'sales' has a confidence of 0.998\n",
      "......Word 'rep' has a confidence of 0.998\n",
      "......Word 'with' has a confidence of 0.989\n",
      "......Word 'relevant' has a confidence of 0.995\n",
      "......Word 'information' has a confidence of 0.995\n",
      "......Word 'even' has a confidence of 0.992\n",
      "...Line # 80 has 9 words and text 'before he or she meets the doctor. It's a' within bounding polygon '[468, 999, 823, 999, 823, 1020, 468, 1019]'\n",
      "......Word 'before' has a confidence of 0.998\n",
      "......Word 'he' has a confidence of 0.997\n",
      "......Word 'or' has a confidence of 0.998\n",
      "......Word 'she' has a confidence of 0.998\n",
      "......Word 'meets' has a confidence of 0.998\n",
      "......Word 'the' has a confidence of 0.999\n",
      "......Word 'doctor.' has a confidence of 0.993\n",
      "......Word 'It's' has a confidence of 0.971\n",
      "......Word 'a' has a confidence of 0.993\n",
      "...Line # 81 has 5 words and text 'totally different, digital game now.\"' within bounding polygon '[468, 1029, 789, 1028, 789, 1050, 468, 1050]'\n",
      "......Word 'totally' has a confidence of 0.995\n",
      "......Word 'different,' has a confidence of 0.992\n",
      "......Word 'digital' has a confidence of 0.994\n",
      "......Word 'game' has a confidence of 0.992\n",
      "......Word 'now.\"' has a confidence of 0.963\n",
      "...Line # 82 has 8 words and text 'KEREN PRIYADARSHINI | Regional Business Lead - Asia,' within bounding polygon '[467, 1067, 760, 1067, 760, 1083, 467, 1083]'\n",
      "......Word 'KEREN' has a confidence of 0.993\n",
      "......Word 'PRIYADARSHINI' has a confidence of 0.984\n",
      "......Word '|' has a confidence of 0.968\n",
      "......Word 'Regional' has a confidence of 0.992\n",
      "......Word 'Business' has a confidence of 0.992\n",
      "......Word 'Lead' has a confidence of 0.989\n",
      "......Word '-' has a confidence of 0.985\n",
      "......Word 'Asia,' has a confidence of 0.96\n",
      "...Line # 83 has 4 words and text 'Worldwide Health | Microsoft' within bounding polygon '[468, 1088, 616, 1088, 616, 1104, 468, 1104]'\n",
      "......Word 'Worldwide' has a confidence of 0.992\n",
      "......Word 'Health' has a confidence of 0.994\n",
      "......Word '|' has a confidence of 0.835\n",
      "......Word 'Microsoft' has a confidence of 0.993\n",
      "...Line # 84 has 7 words and text 'EMBRACING DIGITAL TRANSFORMATION IN LIFE SCIENCES ORGANIZATIONS' within bounding polygon '[76, 1140, 452, 1139, 452, 1153, 76, 1153]'\n",
      "......Word 'EMBRACING' has a confidence of 0.992\n",
      "......Word 'DIGITAL' has a confidence of 0.992\n",
      "......Word 'TRANSFORMATION' has a confidence of 0.992\n",
      "......Word 'IN' has a confidence of 0.994\n",
      "......Word 'LIFE' has a confidence of 0.992\n",
      "......Word 'SCIENCES' has a confidence of 0.992\n",
      "......Word 'ORGANIZATIONS' has a confidence of 0.992\n",
      "...Line # 85 has 1 words and text '2' within bounding polygon '[811, 1138, 824, 1139, 824, 1154, 810, 1154]'\n",
      "......Word '2' has a confidence of 0.992\n",
      "----Detected #16 paragraphs in the document----\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [259, 55, 826, 55, 826, 134, 259, 134]}] bounding region\n",
      "...with content: 'While healthcare is still in the early stages of its Al journey, we are seeing pharmaceutical and other life sciences organizations making major investments in Al and related technologies.\"'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [258, 151, 637, 151, 637, 167, 258, 167]}] bounding region\n",
      "...with content: 'TOM LAWRY | National Director for Al, Health and Life Sciences | Microsoft'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [75, 240, 441, 240, 441, 403, 75, 403]}] bounding region\n",
      "...with content: 'As pharmaceutical and other life sciences organizations invest in and deploy advanced technologies, they are beginning to see benefits in diverse areas across their organizations. Companies are looking to incorporate automation and continuing smart factory investments to reduce costs in drug discovery, research and development, and manufacturing and supply chain management. Many life sciences organizations are also choosing to stay with more virtual approaches in the \"new normal\" - particularly in clinical trials and sales and marketing areas.'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [76, 422, 285, 422, 285, 469, 76, 469]}] bounding region\n",
      "...with content: 'Enhancing the patient and provider experience'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [75, 481, 442, 480, 442, 643, 75, 644]}] bounding region\n",
      "...with content: 'Clinical trial sponsors are continually seeking to make clinical trials faster and to improve the experience for patients and physicians. The COVID-19 pandemic has accelerated the adoption of decentralized clinical trials, with an increase in trial activities conducted remotely and in participants' homes. In a Mckinsey survey,1 up to 98 percent of patients reported satisfaction with telemedicine. In the same report, 72 percent of physicians surveyed reported similar or better experiences with remote engagement compared with in-person visits.'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [74, 657, 445, 658, 445, 765, 74, 764]}] bounding region\n",
      "...with content: 'The shift of trial activities closer to patients has been enabled by a myriad of evolving technologies and services (e.g., electronic consent, telehealth and remote patient monitoring). The aim to use technology to improve the patient experience and convenience has also broadened trial access to reach a broader, more diverse patient population.'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [74, 779, 438, 779, 438, 905, 74, 905]}] bounding region\n",
      "...with content: '\"It's an interesting and exciting time right now,\" said Keren Priyadarshini, Regional Business Lead - Asia, Worldwide Health, Microsoft. \"It used to be that physicians were key. Now, suddenly, patients are feeling empowered by technology. Pharmaceutical companies and other life sciences companies are realizing they have to pay attention to the patient experience in addition to the physician experience.\"'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [74, 918, 443, 918, 443, 1098, 74, 1098]}] bounding region\n",
      "...with content: 'Enhanced patient experiences can be delivered in many different ways. One example of a life sciences product that leverages the intelligent cloud to directly affect the patient experience is the Tandem® Diabetes Care insulin pump. The Tandem® t:slim X2 insulin pump with Basal-IQ technology enables patients with Type 1 diabetes to predict and prevent the low levels of blood sugar that cause hypoglycemia.2 The algorithm-driven, software- updatable pump improves the patient experience by automating chronic disease management and eliminating the need for constant finger pricks to check glucose levels.'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [465, 240, 812, 239, 812, 330, 465, 331]}] bounding region\n",
      "...with content: 'Tandem was able to create and deploy this innovation by leveraging the Al and machine learning capabilities of the intelligent cloud. As Al and other technologies continue to advance, potential use cases will multiply. \"Speed to value is going to continue to accelerate,\" said Lawry.'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [466, 344, 823, 344, 823, 488, 466, 488]}] bounding region\n",
      "...with content: 'In addition to enhancing the patient experience, pharmaceutical and other life sciences companies can leverage advanced technologies to improve relationships with providers. For example, COVID-19 is driving changes in the way companies interact with clinicians. Prior to COVID-19, 75 percent of physicians preferred in-person sales visits from medtech reps; likewise, 77 percent of physicians preferred in- person sales visits from pharma reps.3'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [468, 502, 835, 502, 835, 627, 468, 627]}] bounding region\n",
      "...with content: 'Since the advent of COVID-19, however, physician preferences are moving toward virtual visits. Only 53 percent of physicians now express a preference for in-person visits from medtech reps and only 40 percent prefer in-person visits from pharma reps.4 That puts the onus on pharmaceutical and life sciences organizations to deliver valuable and engaging virtual visits to providers.'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [467, 641, 825, 641, 825, 767, 467, 767]}] bounding region\n",
      "...with content: 'One way to do that is to leverage text analytics capabilities to enhance the provider information stored in the organization's customer relationship management (CRM) system. For example, a rep setting up a visit with 'Dr. X' could run text analytics on publicly available resources on the web to identify on which specific topics Dr. X has been writing about and commenting. \"All kinds of publicly available information can'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [466, 828, 830, 828, 830, 1050, 466, 1050]}] bounding region\n",
      "...with content: 'All kinds of publicly available information can be mined with text analytics technology, which can be used to arm the sales rep with relevant information even before he or she meets the doctor. It's a totally different, digital game now.\"'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [467, 1067, 760, 1067, 760, 1104, 467, 1104]}] bounding region\n",
      "...with content: 'KEREN PRIYADARSHINI | Regional Business Lead - Asia, Worldwide Health | Microsoft'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [76, 1139, 452, 1139, 452, 1153, 76, 1153]}] bounding region\n",
      "...with content: 'EMBRACING DIGITAL TRANSFORMATION IN LIFE SCIENCES ORGANIZATIONS'\n",
      "Found paragraph within [{'pageNumber': 1, 'polygon': [810, 1138, 824, 1138, 824, 1154, 810, 1154]}] bounding region\n",
      "...with content: '2'\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from azure.core.exceptions import HttpResponseError\n",
    "    from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "    try:\n",
    "        load_dotenv(find_dotenv())\n",
    "        analyze_read()\n",
    "    except HttpResponseError as error:\n",
    "        # Examples of how to check an HttpResponseError\n",
    "        # Check by error code:\n",
    "        if error.error is not None:\n",
    "            if error.error.code == \"InvalidImage\":\n",
    "                print(f\"Received an invalid image error: {error.error}\")\n",
    "            if error.error.code == \"InvalidRequest\":\n",
    "                print(f\"Received an invalid request error: {error.error}\")\n",
    "            # Raise the error again after printing it\n",
    "            raise\n",
    "        # If the inner error is None and then it is possible to check the message to get more information:\n",
    "        if \"Invalid request\".casefold() in error.message.casefold():\n",
    "            print(f\"Uh-oh! Seems there was an invalid request: {error}\")\n",
    "        # Raise the error again\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring formular extraction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeOutputOption, AnalyzeResult, DocumentAnalysisFeature\n",
    "\n",
    "\n",
    "document_intelligence_client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "with open(\"./docs/sees_gpt_test.pdf\", \"rb\") as f:\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-read\",\n",
    "        analyze_request=f,\n",
    "        features=[DocumentAnalysisFeature.FORMULAS],\n",
    "        output=[AnalyzeOutputOption.PDF],\n",
    "        content_type=\"application/octet-stream\",\n",
    "    )\n",
    "result: AnalyzeResult = poller.result()\n",
    "operation_id = poller.details[\"operation_id\"]\n",
    "\n",
    "# response = document_intelligence_client.get_analyze_result_pdf(model_id=result.model_id, result_id=operation_id)\n",
    "# with open(\"analyze_result.pdf\", \"wb\") as writer:\n",
    "#     writer.writelines(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('analysis.json', 'w') as json_file:\n",
    "    json.dump(result.as_dict(), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formular extraction from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_and_formulas(file_path):\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-read\",\n",
    "            analyze_request=f,\n",
    "            features=[DocumentAnalysisFeature.FORMULAS],\n",
    "            # output=[AnalyzeOutputOption.PDF],\n",
    "            content_type=\"application/octet-stream\",\n",
    "        )\n",
    "    result: AnalyzeResult = poller.result()\n",
    "\n",
    "    all_formulars = []\n",
    "    for page in result.pages:\n",
    "        print(f\"----Formulas detected from page #{page.page_number}----\")\n",
    "        if page.formulas:\n",
    "            all_formulars.extend([f.value for f in page.formulas])\n",
    "\n",
    "    print()\n",
    "    assert len(all_formulars)==result.content.count(\":formula:\")\n",
    "    print(\"Formula extraction complete!\")\n",
    "    print()\n",
    "\n",
    "    extract = result.content\n",
    "    for formular in all_formulars:\n",
    "        extract = extract.replace(\":formula:\", formular, 1)\n",
    "\n",
    "    return extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Formulas detected from page #1----\n",
      "----Formulas detected from page #2----\n",
      "----Formulas detected from page #3----\n",
      "----Formulas detected from page #4----\n",
      "----Formulas detected from page #5----\n",
      "----Formulas detected from page #6----\n",
      "----Formulas detected from page #7----\n",
      "----Formulas detected from page #8----\n",
      "----Formulas detected from page #9----\n",
      "----Formulas detected from page #10----\n",
      "\n",
      "Formula extraction complete!\n",
      "\n",
      "13 Partial Derivatives\n",
      "To this point, with the exception of the occasional section in the last chapter, we've been working almost exclusively with functions of a single variable. It is now time to formally start multi-variable Calculus, i.e. Calculus involving functions of two or more variables. We will be covering the same basic topics as we do with single variable Calculus. Namely, limits, derivatives and integrals.\n",
      "In this chapter we will open up with a quick section discussing taking limits of multi-variable func- tions. We will only be covering limits of multi-variable functions with a single chapter because, as we'll see, many of the concepts from single variable limits still hold, with some natural extensions of course. However, as we'll also see the work will often be significantly longer/harder and so we won't be spending a lot of time discussing limits of multi-variable functions. Luckily enough for us we also won't need to worry all that much about limits of multi-variable functions so the quick discussion of limits in this chapter will suffice.\n",
      "The rest of the chapter will be discussing how to take derivatives of multi-variable functions. We want to keep the \"main\" interpretation of derivatives, namely the derivative will still give the rate of change of the function. The issue here is that because we have multiple variables the function can have differing rates of change depending on how we allow the various variables to change.\n",
      "So, to start out the derivative discussion we will start by defining the partial derivative. These will restrict just how we allow the various variables to change. We will eventually introduce the directional derivative which will allow the variables to change in any arbitrary manner. In the process of introducing the idea of a directional derivative we'll also introduce the concept of a gradient of a function. The gradient will arise in quite a few sections throughout the rest of this multi-variable Calculus material, including integrals.\n",
      "Finally, as we'll see, if you can take derivatives of single variable functions then you have the majority of the knowledge that you need to take derivatives of multi-variable functions. There are, however, some subtleties that we'll need to remember to deal with. Those subtleties are, generally, the issues that most students run into when taking derivatives of multi-variable functions.\n",
      "990\n",
      "Section 13.1 : Limits\n",
      "Chapter 13 : Partial Derivatives\n",
      "13.1 Limits\n",
      "In this section we will take a look at limits involving functions of more than one variable. In fact, we will concentrate mostly on limits of functions of two variables, but the ideas can be extended out to functions with more than two variables.\n",
      "Before getting into this let's briefly recall how limits of functions of one variable work. We say that,\n",
      "\\lim _ { x \\rightarrow a } f \\left( x \\right) = L\n",
      "provided,\n",
      "\\lim _ { x \\rightarrow a ^ { + } } f \\left( x \\right) = \\lim _ { x \\rightarrow a ^ { - } } f \\left( x \\right) = L\n",
      "Also, recall that,\n",
      "\\lim _ { x \\rightarrow a ^ { + } } f \\left( x \\right)\n",
      "is a right hand limit and requires us to only look at values o f \\quad x \\quad t h a t are greater than a. Like- wise,\n",
      "\\lim _ { x \\rightarrow a ^ { - } } f \\left( x \\right)\n",
      "is a left hand limit and requires us to only look at values of x that are less than a.\n",
      "In other words, we will have \\lim _ { x \\rightarrow a } f \\left( x \\right) = L provided f \\left( x \\right) approaches L as we move in towards x = a (without letting \\left. x = a \\right) from both sides.\n",
      "Now, notice that in this case there are only two paths that we can take as we move in towards x = a . We can either move in from the left or we can move in from the right. Then in order for the limit of a function of one variable to exist the function must be approaching the same value as we take each of these paths in towards x = a.\n",
      "With functions of two variables we will have to do something similar, except this time there is (potentially) going to be a lot more work involved. Let's first address the notation and get a feel for just what we're going to be asking for in these kinds of limits.\n",
      "We will be asking to take the limit of the function f \\left( x , y \\right) as x approaches a and as y approaches b. This can be written in several ways. Here are a couple of the more standard notations.\n",
      "\\lim _ { \\binom { x \\rightarrow a } { y \\rightarrow b } } f \\left( x , y \\right) \\lim _ { \\left( x , y \\right) \\rightarrow \\left( a , b \\right) } f \\left( x , y \\right)\n",
      "We will use the second notation more often than not in this course. The second notation is also a little more helpful in illustrating what we are really doing here when we are taking a limit. In taking a limit of a function of two variables we are really asking what the value of f \\left( x , y \\right) is doing as we move the point \\left( x , y \\right) in closer and closer to the point \\left( a , b \\right) without actually letting it be \\left( a , b \\right) .\n",
      "Just like with limits of functions of one variable, in order for this limit to exist, the function must be approaching the same value regardless of the path that we take as we move in towards \\left( a , b \\right) . The problem that we are immediately faced with is that there are literally an infinite number of paths\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 991 -\n",
      "Chapter 13 : Partial Derivatives\n",
      "Section 13.1 : Limits\n",
      "that we can take as we move in towards \\left( a , b \\right) . Here are a few examples of paths that we could take.\n",
      "y\n",
      "2\n",
      "b\n",
      "- x\n",
      "a\n",
      "We put in a couple of straight line paths as well as a couple of \"stranger\" paths that aren't straight line paths. Also, we only included 6 paths here and as you can see simply by varying the slope of the straight line paths there are an infinite number of these and then we would need to consider paths that aren't straight line paths.\n",
      "In other words, to show that a limit exists we would technically need to check an infinite number of paths and verify that the function is approaching the same value regardless of the path we are using to approach the point.\n",
      "Luckily for us however we can use one of the main ideas from Calculus I limits to help us take limits here.\n",
      "Definition\n",
      "A function f \\left( x , y \\right) is continuous at the point \\left( a , b \\right) if,\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( a , b \\right) } f \\left( x , y \\right) = f \\left( a , b \\right)\n",
      "From a graphical standpoint this definition means the same thing as it did when we first saw con- tinuity in Calculus I. A function will be continuous at a point if the graph doesn't have any holes or breaks at that point.\n",
      "How can this help us take limits? Well, just as in Calculus I, if you know that a function is continuous at \\left( a , b \\right) then you also know that\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( a , b \\right) } f \\left( x , y \\right) = f \\left( a , b \\right)\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 992 -\n",
      "Section 13.1 : Limits\n",
      "Chapter 13 : Partial Derivatives\n",
      "must be true. So, if we know that a function is continuous at a point then all we need to do to take the limit of the function at that point is to plug the point into the function.\n",
      "All the standard functions that we know to be continuous are still continuous even if we are plugging in more than one variable now. We just need to watch out for division by zero, square roots of negative numbers, logarithms of zero or negative numbers, etc.\n",
      "Note that the idea about paths is one that we shouldn't forget since it is a nice way to determine if a limit doesn't exist. If we can find two paths upon which the function approaches different values as we get near the point then we will know that the limit doesn't exist.\n",
      "Let's take a look at a couple of examples.\n",
      "Example 1\n",
      "Determine if the following limits exist or not. If they do exist give the value of the limit.\n",
      "(a) \\lim _ { \\left( x , y , z \\right) \\rightarrow \\left( 2 , 1 , - 1 \\right) } \\left( 3 x ^ { 2 } z + y x \\cos \\left( \\pi x - \\pi z \\right) \\right)\n",
      "(b) \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 5 , 1 \\right) } \\frac { x y } { x + y }\n",
      "Solution\n",
      "(a) \\lim _ { \\left( x , y , z \\right) \\rightarrow \\left( 2 , 1 , - 1 \\right) } \\left( 3 x ^ { 2 } z + y x \\cos \\left( \\pi x - \\pi z \\right) \\right) ⌘\n",
      "Okay, in this case the function is continuous at the point in question and so all we need to do is plug in the values and we're done.\n",
      "\\lim _ { \\left( x , y , z \\right) \\rightarrow \\left( 2 , 1 , - 1 \\right) } \\left( 3 x ^ { 2 } z + y x \\cos \\left( \\pi x - \\pi z \\right) \\right) = 3 \\left( 2 \\right) ^ { 2 } \\left( - 1 \\right) + \\left( 1 \\right) \\left( 2 \\right) \\cos \\left( 2 \\pi + \\pi \\right) = - 1 4 \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 5 , 1 \\right) } \\frac { x y } { x + y }\n",
      "(b)\n",
      "In this case the function will not be continuous along the line y = - \\quad x since we will get division by zero when this is true. However, for this problem that is not something that we will need to worry about since the point that we are taking the limit at isn't on this line.\n",
      "Therefore, all that we need to do is plug in the point since the function is continuous at this point.\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 5 , 1 \\right) } \\frac { x y } { x + y } = \\frac { 5 } { 6 }\n",
      "In the previous example there wasn't really anything to the limits. The functions were continuous at\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 993 -\n",
      "Chapter 13 : Partial Derivatives\n",
      "Section 13.1 : Limits\n",
      "the point in question and so all we had to do was plug in the point. That, of course, will not always be the case so let's work a few examples that are more typical of those you'll see here.\n",
      "Example 2\n",
      "Determine if the following limit exist or not. If they do exist give the value of the limit.\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 1 , 1 \\right) } \\frac { 2 x ^ { 2 } - x y - y ^ { 2 } } { x ^ { 2 } - y ^ { 2 } }\n",
      "Solution\n",
      "In this case the function is not continuous at the point in question (clearly division by zero). However, that does not mean that the limit can't be done. We saw many examples of this in Calculus I where the function was not continuous at the point we were looking at and yet the limit did exist.\n",
      "In the case of this limit notice that we can factor both the numerator and denominator of the function as follows,\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 1 , 1 \\right) } \\frac { 2 x ^ { 2 } - x y - y ^ { 2 } } { x ^ { 2 } - y ^ { 2 } } = \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 1 , 1 \\right) } \\frac { \\left( 2 x + y \\right) \\left( x - y \\right) } { \\left( x - y \\right) \\left( x + y \\right) } = \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 1 , 1 \\right) } \\frac { 2 x + y } { x + y }\n",
      "So, just as we saw in many examples in Calculus I, upon factoring and canceling common factors we arrive at a function that in fact we can take the limit of. So, to finish out this example all we need to do is actually take the limit.\n",
      "Taking the limit gives,\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 1 , 1 \\right) } \\frac { 2 x ^ { 2 } - x y - y ^ { 2 } } { x ^ { 2 } - y ^ { 2 } } = \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 1 , 1 \\right) } \\frac { 2 x + y } { x + y } = \\frac { 3 } { 2 }\n",
      "Before we move on to the next set of examples we should note that the situation in the previous example is what generally happened in many limit examples/problems in Calculus I. In Calculus III however, this tends to be the exception in the examples/problems as the next set of examples will show. In other words, do not expect most of these types of limits to just factor and then exist as they did in Calculus I.\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 994 -\n",
      "Section 13.1 : Limits\n",
      "Chapter 13 : Partial Derivatives\n",
      "Example 3\n",
      "Determine if the following limits exist or not. If they do exist give the value of the limit.\n",
      "(a) \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 2 } y ^ { 2 } } { x ^ { 4 } + 3 y ^ { 4 } }\n",
      "(b) \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 3 } y } { x ^ { 6 } + y ^ { 2 } }\n",
      "Solution\n",
      "(a) \\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 2 } y ^ { 2 } } { x ^ { 4 } + 3 y ^ { 4 } }\n",
      "In this case the function is not continuous at the point in question and so we can't just plug in the point. Also, note that, unlike the previous example, we can't factor this function and do some canceling so that the limit can be taken.\n",
      "Therefore, since the function is not continuous at the point and because there is no factoring we can do, there is at least a chance that the limit doesn't exist. If we could find two different paths to approach the point that gave different values for the limit then we would know that the limit didn't exist. Two of the more common paths to check are t h e \\quad x \\quad a n d y-axis so let's try those.\n",
      "Before actually doing this we need to address just what exactly do we mean when we say that we are going to approach a point along a path. When we approach a point along a path we will do this by either f i x i n g \\quad x \\quad o r \\quad y \\quad o r \\quad b y relating x and y through some function. In this way we can reduce the limit to just a limit involving a single variable which we know how to do from Calculus I.\n",
      "So, let's see what happens along the x-axis. If we are going to approach \\left( 0 , 0 \\right) along the x-axis we can take advantage of the fact that that along the x-axis we know that y = 0 . This means that, along the x-axis, we will plug in y = 0 into the function and then take the limit a s \\quad x approaches zero.\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 2 } y ^ { 2 } } { x ^ { 4 } + 3 y ^ { 4 } } = \\lim _ { \\left( x , 0 \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 2 } \\left( 0 \\right) ^ { 2 } } { x ^ { 4 } + 3 \\left( 0 \\right) ^ { 4 } } = \\lim _ { \\left( x , 0 \\right) \\rightarrow \\left( 0 , 0 \\right) } 0 = 0\n",
      "So, along the x-axis the function will approach zero as we move in towards the origin. Now, let's try the y-axis. Along this axis we have x = 0 and so the limit becomes,\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 2 } y ^ { 2 } } { x ^ { 4 } + 3 y ^ { 4 } } = \\lim _ { \\left( 0 , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { \\left( 0 \\right) ^ { 2 } y ^ { 2 } } { \\left( 0 \\right) ^ { 4 } + 3 y ^ { 4 } } = \\lim _ { \\left( 0 , y \\right) \\rightarrow \\left( 0 , 0 \\right) } 0 = 0\n",
      "So, the same limit along two paths. Don't misread this. This does NOT say that the\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 995 -\n",
      "Section 13.1 : Limits\n",
      "Chapter 13 : Partial Derivatives\n",
      "limit exists and has a value of zero. This only means that the limit happens to have the same value along two paths.\n",
      "Let's take a look at a third fairly common path to take a look at. In this case we'll move in towards the origin along the path y = x . This is what we meant previously about relating x and y through a function.\n",
      "To do this we will replace all the y ^ { \\prime } \\mathrm { s } with x's and then let x approach zero. Let's take a look at this limit.\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 2 } y ^ { 2 } } { x ^ { 4 } + 3 y ^ { 4 } } = \\lim _ { \\left( x , x \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 2 } x ^ { 2 } } { x ^ { 4 } + 3 x ^ { 4 } } = \\lim _ { \\left( x , x \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 4 } } { 4 x ^ { 4 } } = \\lim _ { \\left( x , x \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { 1 } { 4 } = \\frac { 1 } { 4 }\n",
      "So, a different value from the previous two paths and this means that the limit can't possibly exist.\n",
      "Note that we can use this idea of moving in towards the origin along a line with the more general path y = m x if we need to.\n",
      "(b)\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 3 } y } { x ^ { 6 } + y ^ { 2 } }\n",
      "Okay, with this last one we again have continuity problems at the origin and again there is no factoring we can do that will allow the limit to be taken. So, again let's see if we can find a couple of paths that give different values of the limit.\n",
      "First, we will use the path y = x . Along this path we have,\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 3 } y } { x ^ { 6 } + y ^ { 2 } } = \\lim _ { \\left( x , x \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 3 } x } { x ^ { 6 } + x ^ { 2 } } = \\lim _ { \\left( x , x \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 4 } } { x ^ { 6 } + x ^ { 2 } } = 0\n",
      "Now, let's try the path y = x ^ { 3 } . Along this path the limit becomes,\n",
      "\\lim _ { \\left( x , y \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 3 } y } { x ^ { 6 } + y ^ { 2 } } = \\lim _ { \\left( x , x ^ { 3 } \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 3 } x ^ { 3 } } { x ^ { 6 } + \\left( x ^ { 3 } \\right) ^ { 2 } } = \\lim _ { \\left( x , x ^ { 3 } \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { x ^ { 6 } } { 2 x ^ { 6 } } = \\lim _ { \\left( x , x ^ { 3 } \\right) \\rightarrow \\left( 0 , 0 \\right) } \\frac { 1 } { 2 } = \\frac { 1 } { 2 }\n",
      "We now have two paths that give different values for the limit and so the limit doesn't exist.\n",
      "As this limit has shown us we can, and often need, to use paths other than lines like we did in the first part of this example.\n",
      "So, as we've seen in the previous example limits are a little different here from those we saw in Calculus I. Limits in multiple variables can be quite difficult to evaluate and we've shown several examples where it took a little work just to show that the limit does not exist.\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 996 -\n",
      "Section 13.2 : Partial Derivatives\n",
      "Chapter 13 : Partial Derivatives\n",
      "13.2 Partial Derivatives\n",
      "Now that we have the brief discussion on limits out of the way we can proceed into taking derivatives of functions of more than one variable. Before we actually start taking derivatives of functions of more than one variable let's recall an important interpretation of derivatives of functions of one variable.\n",
      "Recall that given a function of one variable, f \\left( x \\right) , the derivative, f ^ { \\prime } \\left( x \\right) , represents the rate of change of the function as x changes. This is an important interpretation of derivatives and we are not going to want to lose it with functions of more than one variable. The problem with functions of more than one variable is that there is more than one variable. In other words, what do we do if we only want one of the variables to change, or if we want more than one of them to change? In fact, if we're going to allow more than one of the variables to change there are then going to be an infinite amount of ways for them to change. For instance, one variable could be changing faster than the other variable(s) in the function. Notice as well that it will be completely possible for the function to be changing differently depending on how we allow one or more of the variables to change.\n",
      "We will need to develop ways, and notations, for dealing with all of these cases. In this section we are going to concentrate exclusively on only changing one of the variables at a time, while the remaining variable(s) are held fixed. We will deal with allowing multiple variables to change in a later section.\n",
      "Because we are going to only allow one of the variables to change taking the derivative will now become a fairly simple process. Let's start off this discussion with a fairly simple function.\n",
      "Let's start with the function f \\left( x , y \\right) = 2 x ^ { 2 } y ^ { 3 } and let's determine the rate at which the function is changing at a point, \\left( a , b \\right) , if we hold y fixed and allow x to vary and \\mathrm { i f } we hold a fixed and allow y to vary.\n",
      "We'll start by looking at the case of holding \\ln g y fixed and allowing x to vary. Since we are interested in the rate of change of the function at \\left( a , b \\right) and are holding y fixed this means that we are going to always have y = b (if we didn't have this then eventually y would have to change in order to get to the point ... ). Doing this will give us a function involving only x ^ { \\prime } \\mathrm { s } and we can define a new function as follows,\n",
      "g \\left( x \\right) = f \\left( x , b \\right) = 2 x ^ { 2 } b ^ { 3 }\n",
      "Now, this is a function of a single variable and at this point all that we are asking is to determine the rate of change of g \\left( x \\right) at x = a . In other words, we want to compute g ^ { \\prime } \\left( a \\right) and since this is a function of a single variable we already know how to do that. Here is the rate of change of the function at \\left( a , b \\right) if we hold y fixed and allow x to vary.\n",
      "g ^ { \\prime } \\left( a \\right) = 4 a b ^ { 3 }\n",
      "We will call g ^ { \\prime } \\left( a \\right) the partial derivative of f \\left( x , y \\right) with respect to x at \\left( a , b \\right) and we will denote it in the following way,\n",
      "f _ { x } \\left( a , b \\right) = 4 a b ^ { 3 }\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 997 -\n",
      "Section 13.2 : Partial Derivatives\n",
      "Chapter 13 : Partial Derivatives\n",
      "Now, let's do it the other way. We will now hold x fixed and allow y to vary. We can do this in a similar way. Since we are holding x fixed it must be fixed at x = a and so we can define a new function of y and then differentiate this as we've always done with functions of one variable.\n",
      "Here is the work for this,\n",
      "h \\left( y \\right) = f \\left( a , y \\right) = 2 a ^ { 2 } y ^ { 3 } \\quad \\Rightarrow \\quad h ^ { \\prime } \\left( b \\right) = 6 a ^ { 2 } b ^ { 2 }\n",
      "In this case we call h ^ { \\prime } \\left( b \\right) the partial derivative of f \\left( x , y \\right) with respect to y at \\left( a , b \\right) and we denote it as follows,\n",
      "f _ { y } \\left( a , b \\right) = 6 a ^ { 2 } b ^ { 2 }\n",
      "Note that these two partial derivatives are sometimes called the first order partial derivatives. Just as with functions of one variable we can have derivatives of all orders. We will be looking at higher order derivatives in a later section.\n",
      "Note that the notation for partial derivatives is different than that for derivatives of functions of a single variable. With functions of a single variable we could denote the derivative with a single prime. However, with partial derivatives we will always need to remember the variable that we are differentiating with respect to and so we will subscript the variable that we differentiated with respect to. We will shortly be seeing some alternate notation for partial derivatives as well.\n",
      "Note as well that we usually don't use the \\left( a , b \\right) notation for partial derivatives as that implies we are working with a specific point which we usually are not doing. The more standard notation is to just continue to use \\left( x , y \\right) . So, the partial derivatives from above will more commonly be written a s ,\n",
      "f _ { x } \\left( x , y \\right) = 4 x y ^ { 3 } f _ { y } \\left( x , y \\right) = 6 x ^ { 2 } y ^ { 2 } and\n",
      "Now, as this quick example has shown taking derivatives of functions of more than one variable is done in pretty much the same manner as taking derivatives of a single variable. To compute f _ { x } \\left( x , y \\right) all we need to do is treat all the y ^ { \\prime } \\mathrm { s } as constants (or numbers) and then differentiate the x's as we've always done. Likewise, to compute f _ { u } \\left( x , y \\right) we will treat all the x ^ { \\prime } \\mathrm { s } \\mathrm { a s } constants and then differentiate the y s as we are used to doing.\n",
      "Before we work any examples let's get the formal definition of the partial derivative out of the way as well as some alternate notation.\n",
      "Since we can think of the two partial derivatives above as derivatives of single variable functions it shouldn't be too surprising that the definition of each is very similar to the definition of the derivative for single variable functions. Here are the formal definitions of the two partial derivatives we looked at above.\n",
      "f _ { x } \\left( x , y \\right) = \\lim _ { h \\rightarrow 0 } \\frac { f \\left( x + h , y \\right) - f \\left( x , y \\right) } { h } \\quad f _ { y } \\left( x , y \\right) = \\lim _ { h \\rightarrow 0 } \\frac { f \\left( x , y + h \\right) - f \\left( x , y \\right) } { h }\n",
      "If you recall the Calculus I definition of the limit these should look familiar as they are very close to the Calculus I definition with a (possibly) obvious change.\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 998 -\n",
      "Section 13.2 : Partial Derivatives\n",
      "Chapter 13 : Partial Derivatives\n",
      "Now let's take a quick look at some of the possible alternate notations for partial derivatives. Given the function z = f \\left( x , y \\right) the following are all equivalent notations,\n",
      "f _ { x } \\left( x , y \\right) = f _ { x } = \\frac { \\partial f } { \\partial x } = \\frac { \\partial } { \\partial x } \\left( f \\left( x , y \\right) \\right) = z _ { x } = \\frac { \\partial z } { \\partial x } = D _ { x } f f _ { y } \\left( x , y \\right) = f _ { y } = \\frac { \\partial f } { \\partial y } = \\frac { \\partial } { \\partial y } \\left( f \\left( x , y \\right) \\right) = z _ { y } = \\frac { \\partial z } { \\partial y } = D _ { y } f\n",
      "For the fractional notation for the partial derivative notice the difference between the partial deriva- tive and the ordinary derivative from single variable calculus.\n",
      "f (x) f ^ { \\prime } \\left( x \\right) = \\frac { d f } { d x } f _ { x } \\left( x , y \\right) = \\frac { \\partial f } { \\partial x } \\text { 8 } f _ { y } \\left( x , y \\right) = \\frac { \\partial f } { \\partial y } 11 f \\left( x , y \\right)\n",
      "Okay, now let's work some examples. When working these examples always keep in mind that we need to pay very close attention to which variable we are differentiating with respect to. This is important because we are going to treat all other variables as constants and then proceed with the derivative as if it was a function of a single variable. If you can remember this you'll find that doing partial derivatives are not much more difficult that doing derivatives of functions of a single variable as we did in Calculus I.\n",
      "Example 1\n",
      "Find all of the first order partial derivatives for the following functions.\n",
      "(a) f \\left( x , y \\right) = x ^ { 4 } + 6 \\sqrt { y } - 1 0\n",
      "(b) w = x ^ { 2 } y - 1 0 y ^ { 2 } z ^ { 3 } + 4 3 x - 7 \\tan \\left( 4 y \\right)\n",
      "(c) h \\left( s , t \\right) = t ^ { 7 } \\ln \\left( s ^ { 2 } \\right) + \\frac { 9 } { t ^ { 3 } } - \\sqrt [ 7 ] { s ^ { 4 } }\n",
      "(d) f \\left( x , y \\right) = \\cos \\left( \\frac { 4 } { x } \\right) e ^ { x ^ { 2 } y - 5 y ^ { 3 } }\n",
      "Solution\n",
      "(a) f \\left( x , y \\right) = x ^ { 4 } + 6 \\sqrt { y } - 1 0\n",
      "Let's first take the derivative with respect to x and remember that as we do so all the y ^ { \\prime } s will be treated as constants. The partial derivative with respect to x is,\n",
      "f _ { x } \\left( x , y \\right) = 4 x ^ { 3 }\n",
      "Notice that the second and the third term differentiate to zero in this case. It should\n",
      "@ Paul Dawkins\n",
      "Calculus\n",
      "- 999 -\n"
     ]
    }
   ],
   "source": [
    "print(extract_texts_and_formulas(\"./docs/sees_gpt_test.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sees_gpt_test.txt\", 'w') as file:\n",
    "    file.write(extract_texts_and_formulas(\"../sees_gpt_test.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting PDF content with Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts(file_path):\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-read\",\n",
    "            analyze_request=f,\n",
    "            # features=[DocumentAnalysisFeature.FORMULAS],\n",
    "            # output=[AnalyzeOutputOption.PDF],\n",
    "            content_type=\"application/octet-stream\",\n",
    "        )\n",
    "    result: AnalyzeResult = poller.result()\n",
    "\n",
    "    # all_formulars = []\n",
    "    # for page in result.pages:\n",
    "    #     print(f\"----Formulas detected from page #{page.page_number}----\")\n",
    "    #     if page.formulas:\n",
    "    #         all_formulars.extend([f.value for f in page.formulas])\n",
    "\n",
    "    # print()\n",
    "    # assert len(all_formulars)==result.content.count(\":formula:\")\n",
    "    # print(\"Formula extraction complete!\")\n",
    "    # print()\n",
    "\n",
    "    extract = result.content\n",
    "    # for formular in all_formulars:\n",
    "    #     extract = extract.replace(\":formula:\", formular, 1)\n",
    "\n",
    "    return extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_content = extract_texts(\"./docs/WHO-doc-snippet.pdf\")\n",
    "with open(\"WHO-doc-snippet-extracted.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(extracted_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzureOCR-for-RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
